{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "341bdaeb-85d7-4960-94bb-88035a98de55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6f4d48c8-a835-43e9-9591-4ea03225556a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"data_cancer.csv\")\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cabf88a1-1d75-4d87-a41c-c3c8431a162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['Unnamed: 32'], axis = 1, inplace = True)\n",
    "dataset.diagnosis.replace(('B', 'M'), (1, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6a87ad65-ed0d-4d2b-a493-ba1f93c103d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7c52f851-2b2c-410d-9cfc-5954afcf9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset.iloc[:, 1:32].values\n",
    "y=dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e5f8b851-808e-4ba2-b643-0de6f8513077",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "# y = lb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "395da76f-5399-45d9-948a-54c36c26abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "scaled = ss.fit_transform(x)\n",
    "lda = LinearDiscriminantAnalysis(n_components= 1)\n",
    "lda.fit(scaled,y) \n",
    "reduced_LDA = lda.transform(scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9d5b91e4-502a-4a1a-b4b4-3334b2891436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>principalcomponent1</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.323927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.319108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.747425</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.048549</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.281158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   principalcomponent1  diagnosis\n",
       "0             3.323927          0\n",
       "1             2.319108          0\n",
       "2             3.747425          0\n",
       "3             4.048549          0\n",
       "4             2.281158          0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_dataset = pd.DataFrame(reduced_LDA,columns=[\"principalcomponent1\"]) \n",
    "lda_dataset[\"diagnosis\"] = y \n",
    "lda_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c31b2aa7-672f-44aa-a5e8-ae9794acb63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0) \n",
    "X_train = lda.fit_transform(X_train,y_train) \n",
    "X_test = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fa99a59e-7d44-420b-b133-34c734458278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples, validate on 171 samples\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s 168us/step - loss: 2.9636 - accuracy: 0.0000e+00 - val_loss: 2.9222 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 2.8912 - accuracy: 0.0452 - val_loss: 2.8495 - val_accuracy: 0.3860\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 2.8193 - accuracy: 0.5779 - val_loss: 2.7782 - val_accuracy: 0.6316\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 2.7488 - accuracy: 0.6256 - val_loss: 2.7079 - val_accuracy: 0.6316\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 2.6793 - accuracy: 0.6256 - val_loss: 2.6389 - val_accuracy: 0.6316\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 2.6112 - accuracy: 0.6256 - val_loss: 2.5710 - val_accuracy: 0.6316\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 2.5441 - accuracy: 0.6256 - val_loss: 2.5046 - val_accuracy: 0.6316\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 2.4786 - accuracy: 0.6256 - val_loss: 2.4396 - val_accuracy: 0.6316\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 2.4145 - accuracy: 0.6256 - val_loss: 2.3758 - val_accuracy: 0.6316\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 2.3515 - accuracy: 0.6256 - val_loss: 2.3135 - val_accuracy: 0.6316\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 2.2901 - accuracy: 0.6256 - val_loss: 2.2527 - val_accuracy: 0.6316\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 2.2303 - accuracy: 0.6256 - val_loss: 2.1936 - val_accuracy: 0.6316\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 2.1720 - accuracy: 0.6256 - val_loss: 2.1358 - val_accuracy: 0.6316\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 2.1152 - accuracy: 0.6256 - val_loss: 2.0797 - val_accuracy: 0.6316\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 2.0599 - accuracy: 0.6256 - val_loss: 2.0249 - val_accuracy: 0.6316\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 2.0061 - accuracy: 0.6256 - val_loss: 1.9720 - val_accuracy: 0.6316\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.9541 - accuracy: 0.6256 - val_loss: 1.9204 - val_accuracy: 0.6316\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.9033 - accuracy: 0.6256 - val_loss: 1.8704 - val_accuracy: 0.6316\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.8542 - accuracy: 0.6256 - val_loss: 1.8221 - val_accuracy: 0.6316\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.8067 - accuracy: 0.6256 - val_loss: 1.7751 - val_accuracy: 0.6316\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.7607 - accuracy: 0.6256 - val_loss: 1.7299 - val_accuracy: 0.6316\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.7162 - accuracy: 0.6256 - val_loss: 1.6863 - val_accuracy: 0.6316\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.6735 - accuracy: 0.6256 - val_loss: 1.6442 - val_accuracy: 0.6316\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 1.6320 - accuracy: 0.6256 - val_loss: 1.6034 - val_accuracy: 0.6316\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.5920 - accuracy: 0.6256 - val_loss: 1.5643 - val_accuracy: 0.6316\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.5535 - accuracy: 0.6256 - val_loss: 1.5263 - val_accuracy: 0.6316\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.5163 - accuracy: 0.6256 - val_loss: 1.4900 - val_accuracy: 0.6316\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.4805 - accuracy: 0.6256 - val_loss: 1.4547 - val_accuracy: 0.6316\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.4459 - accuracy: 0.6256 - val_loss: 1.4207 - val_accuracy: 0.6316\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.4125 - accuracy: 0.6256 - val_loss: 1.3881 - val_accuracy: 0.6316\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.3804 - accuracy: 0.6256 - val_loss: 1.3566 - val_accuracy: 0.6316\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.3494 - accuracy: 0.6256 - val_loss: 1.3263 - val_accuracy: 0.6316\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 1.3196 - accuracy: 0.6256 - val_loss: 1.2971 - val_accuracy: 0.6316\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.2908 - accuracy: 0.6256 - val_loss: 1.2689 - val_accuracy: 0.6316\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.2630 - accuracy: 0.6256 - val_loss: 1.2417 - val_accuracy: 0.6316\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.2361 - accuracy: 0.6256 - val_loss: 1.2154 - val_accuracy: 0.6316\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.2101 - accuracy: 0.6256 - val_loss: 1.1900 - val_accuracy: 0.6316\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.1851 - accuracy: 0.6256 - val_loss: 1.1654 - val_accuracy: 0.6316\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 1.1607 - accuracy: 0.6256 - val_loss: 1.1416 - val_accuracy: 0.6316\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.1371 - accuracy: 0.6256 - val_loss: 1.1185 - val_accuracy: 0.6316\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 1.1143 - accuracy: 0.6256 - val_loss: 1.0963 - val_accuracy: 0.6316\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 1.0923 - accuracy: 0.6256 - val_loss: 1.0747 - val_accuracy: 0.6316\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 1.0709 - accuracy: 0.6256 - val_loss: 1.0539 - val_accuracy: 0.6316\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 1.0502 - accuracy: 0.6256 - val_loss: 1.0336 - val_accuracy: 0.6316\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.0301 - accuracy: 0.6256 - val_loss: 1.0140 - val_accuracy: 0.6316\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.0105 - accuracy: 0.6256 - val_loss: 0.9949 - val_accuracy: 0.6316\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.9915 - accuracy: 0.6256 - val_loss: 0.9763 - val_accuracy: 0.6316\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.9730 - accuracy: 0.6256 - val_loss: 0.9583 - val_accuracy: 0.6316\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.9550 - accuracy: 0.6256 - val_loss: 0.9407 - val_accuracy: 0.6316\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.9375 - accuracy: 0.6256 - val_loss: 0.9237 - val_accuracy: 0.6316\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.9204 - accuracy: 0.6256 - val_loss: 0.9071 - val_accuracy: 0.6316\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.9039 - accuracy: 0.6256 - val_loss: 0.8909 - val_accuracy: 0.6433\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.8877 - accuracy: 0.6256 - val_loss: 0.8752 - val_accuracy: 0.6433\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.8718 - accuracy: 0.6281 - val_loss: 0.8598 - val_accuracy: 0.6433\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.8565 - accuracy: 0.6332 - val_loss: 0.8447 - val_accuracy: 0.6608\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.8414 - accuracy: 0.6482 - val_loss: 0.8302 - val_accuracy: 0.6842\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.8267 - accuracy: 0.6759 - val_loss: 0.8160 - val_accuracy: 0.7135\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.8125 - accuracy: 0.6985 - val_loss: 0.8020 - val_accuracy: 0.7193\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.7985 - accuracy: 0.7136 - val_loss: 0.7885 - val_accuracy: 0.7310\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 0.7847 - accuracy: 0.7362 - val_loss: 0.7751 - val_accuracy: 0.7544\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.7714 - accuracy: 0.7563 - val_loss: 0.7621 - val_accuracy: 0.7836\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.7582 - accuracy: 0.7814 - val_loss: 0.7493 - val_accuracy: 0.7895\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.7453 - accuracy: 0.7864 - val_loss: 0.7370 - val_accuracy: 0.7953\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.7329 - accuracy: 0.8065 - val_loss: 0.7247 - val_accuracy: 0.8187\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.7206 - accuracy: 0.8241 - val_loss: 0.7128 - val_accuracy: 0.8304\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.7084 - accuracy: 0.8266 - val_loss: 0.7011 - val_accuracy: 0.8596\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.6966 - accuracy: 0.8367 - val_loss: 0.6896 - val_accuracy: 0.8713\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.6850 - accuracy: 0.8492 - val_loss: 0.6785 - val_accuracy: 0.8772\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.6737 - accuracy: 0.8643 - val_loss: 0.6675 - val_accuracy: 0.8830\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.6626 - accuracy: 0.8719 - val_loss: 0.6567 - val_accuracy: 0.8830\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.6517 - accuracy: 0.8819 - val_loss: 0.6462 - val_accuracy: 0.8830\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.6409 - accuracy: 0.8945 - val_loss: 0.6358 - val_accuracy: 0.8830\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.6304 - accuracy: 0.9095 - val_loss: 0.6258 - val_accuracy: 0.8830\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.6202 - accuracy: 0.9196 - val_loss: 0.6158 - val_accuracy: 0.8889\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.6101 - accuracy: 0.9221 - val_loss: 0.6062 - val_accuracy: 0.9006\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.6003 - accuracy: 0.9271 - val_loss: 0.5966 - val_accuracy: 0.9064\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.5905 - accuracy: 0.9322 - val_loss: 0.5873 - val_accuracy: 0.9181\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.5812 - accuracy: 0.9347 - val_loss: 0.5782 - val_accuracy: 0.9181\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.5718 - accuracy: 0.9372 - val_loss: 0.5692 - val_accuracy: 0.9181\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.5627 - accuracy: 0.9397 - val_loss: 0.5605 - val_accuracy: 0.9181\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.5538 - accuracy: 0.9397 - val_loss: 0.5520 - val_accuracy: 0.9240\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.5452 - accuracy: 0.9422 - val_loss: 0.5435 - val_accuracy: 0.9240\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.5366 - accuracy: 0.9447 - val_loss: 0.5353 - val_accuracy: 0.9240\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.5282 - accuracy: 0.9447 - val_loss: 0.5272 - val_accuracy: 0.9357\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.5199 - accuracy: 0.9447 - val_loss: 0.5193 - val_accuracy: 0.9415\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.5118 - accuracy: 0.9447 - val_loss: 0.5115 - val_accuracy: 0.9415\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.5039 - accuracy: 0.9447 - val_loss: 0.5040 - val_accuracy: 0.9532\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.4962 - accuracy: 0.9447 - val_loss: 0.4966 - val_accuracy: 0.9532\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.4887 - accuracy: 0.9497 - val_loss: 0.4892 - val_accuracy: 0.9532\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.4811 - accuracy: 0.9497 - val_loss: 0.4821 - val_accuracy: 0.9532\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.4739 - accuracy: 0.9497 - val_loss: 0.4751 - val_accuracy: 0.9532\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.4668 - accuracy: 0.9548 - val_loss: 0.4683 - val_accuracy: 0.9532\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.4597 - accuracy: 0.9573 - val_loss: 0.4616 - val_accuracy: 0.9532\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.4529 - accuracy: 0.9573 - val_loss: 0.4551 - val_accuracy: 0.9532\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.4462 - accuracy: 0.9623 - val_loss: 0.4486 - val_accuracy: 0.9591\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.4396 - accuracy: 0.9623 - val_loss: 0.4424 - val_accuracy: 0.9591\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.4333 - accuracy: 0.9623 - val_loss: 0.4363 - val_accuracy: 0.9591\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 0.4270 - accuracy: 0.9623 - val_loss: 0.4302 - val_accuracy: 0.9591\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.4208 - accuracy: 0.9623 - val_loss: 0.4244 - val_accuracy: 0.9591\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.4149 - accuracy: 0.9623 - val_loss: 0.4187 - val_accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "modelSeq = Sequential()\n",
    "modelSeq.add(Dense(10, input_dim=1,activation='softmax')) \n",
    "modelSeq.add(Dense(20, activation='softmax')) \n",
    "modelSeq.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) \n",
    "history=modelSeq.fit(X_train, y_train,epochs=100, validation_data=(X_test,y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "21e444b3-506e-4861-b3e4-20e6d7b42e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 23us/step\n",
      "PCA - Neural Network Accuracy = 96.49%\n"
     ]
    }
   ],
   "source": [
    "pred_ANN = modelSeq.predict(X_test) \n",
    "seqEvaluate=modelSeq.evaluate(X_test,y_test)[1] \n",
    "print(\"PCA - Neural Network Accuracy = {0:.2f}%\".format(seqEvaluate*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "79b19d75-0a14-49d0-b352-de18e169f404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Model Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='test accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
