{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data_cancer.csv',sep=',')\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop([\"Unnamed: 32\",\"id\"],axis=1,inplace=True) #kolom dengan nama unamed tidak digunakan karena hanya berisikan Not a Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.diagnosis.replace(('B', 'M'), (1, 0), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset.iloc[:, 1:32].values\n",
    "y=dataset.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler() \n",
    "scaler = ss.fit_transform(x) \n",
    "fa = FactorAnalysis(n_components= 2) \n",
    "fa.fit(scaler,y) \n",
    "X_reduced_fa = fa.transform(scaler) \n",
    "x_reduced= fa.fit_transform(scaler,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0) \n",
    "X_train = fa.fit_transform(X_train,y_train)\n",
    "X_test = fa.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples, validate on 171 samples\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s 186us/step - loss: 3.0003 - accuracy: 0.0000e+00 - val_loss: 2.9585 - val_accuracy: 0.0994\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 2.9306 - accuracy: 0.4523 - val_loss: 2.8891 - val_accuracy: 0.6257\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 2.8618 - accuracy: 0.6231 - val_loss: 2.8208 - val_accuracy: 0.6316\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 2.7943 - accuracy: 0.6256 - val_loss: 2.7538 - val_accuracy: 0.6316\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 2.7280 - accuracy: 0.6256 - val_loss: 2.6879 - val_accuracy: 0.6316\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 2.6628 - accuracy: 0.6256 - val_loss: 2.6234 - val_accuracy: 0.6316\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 2.5990 - accuracy: 0.6256 - val_loss: 2.5602 - val_accuracy: 0.6316\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 46us/step - loss: 2.5366 - accuracy: 0.6256 - val_loss: 2.4985 - val_accuracy: 0.6316\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 60us/step - loss: 2.4758 - accuracy: 0.6256 - val_loss: 2.4381 - val_accuracy: 0.6316\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 60us/step - loss: 2.4161 - accuracy: 0.6256 - val_loss: 2.3792 - val_accuracy: 0.6316\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 2.3580 - accuracy: 0.6256 - val_loss: 2.3218 - val_accuracy: 0.6316\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 2.3014 - accuracy: 0.6256 - val_loss: 2.2662 - val_accuracy: 0.6316\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 2.2466 - accuracy: 0.6256 - val_loss: 2.2121 - val_accuracy: 0.6316\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 2.1933 - accuracy: 0.6256 - val_loss: 2.1592 - val_accuracy: 0.6316\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 2.1413 - accuracy: 0.6256 - val_loss: 2.1084 - val_accuracy: 0.6316\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 2.0913 - accuracy: 0.6256 - val_loss: 2.0588 - val_accuracy: 0.6316\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 2.0425 - accuracy: 0.6256 - val_loss: 2.0106 - val_accuracy: 0.6316\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.9952 - accuracy: 0.6256 - val_loss: 1.9642 - val_accuracy: 0.6316\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.9496 - accuracy: 0.6256 - val_loss: 1.9196 - val_accuracy: 0.6316\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.9058 - accuracy: 0.6256 - val_loss: 1.8766 - val_accuracy: 0.6316\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 1.8636 - accuracy: 0.6256 - val_loss: 1.8351 - val_accuracy: 0.6316\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.8230 - accuracy: 0.6256 - val_loss: 1.7954 - val_accuracy: 0.6316\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.7840 - accuracy: 0.6256 - val_loss: 1.7571 - val_accuracy: 0.6316\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.7463 - accuracy: 0.6256 - val_loss: 1.7201 - val_accuracy: 0.6316\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.7101 - accuracy: 0.6256 - val_loss: 1.6848 - val_accuracy: 0.6316\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.6755 - accuracy: 0.6256 - val_loss: 1.6508 - val_accuracy: 0.6316\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.6421 - accuracy: 0.6256 - val_loss: 1.6182 - val_accuracy: 0.6316\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.6103 - accuracy: 0.6256 - val_loss: 1.5869 - val_accuracy: 0.6316\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.5795 - accuracy: 0.6256 - val_loss: 1.5569 - val_accuracy: 0.6316\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 1.5501 - accuracy: 0.6256 - val_loss: 1.5282 - val_accuracy: 0.6316\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 1.5219 - accuracy: 0.6256 - val_loss: 1.5006 - val_accuracy: 0.6316\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 58us/step - loss: 1.4949 - accuracy: 0.6256 - val_loss: 1.4742 - val_accuracy: 0.6316\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.4690 - accuracy: 0.6256 - val_loss: 1.4489 - val_accuracy: 0.6316\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.4442 - accuracy: 0.6256 - val_loss: 1.4246 - val_accuracy: 0.6316\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.4204 - accuracy: 0.6256 - val_loss: 1.4014 - val_accuracy: 0.6316\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.3975 - accuracy: 0.6256 - val_loss: 1.3790 - val_accuracy: 0.6316\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 1.3756 - accuracy: 0.6256 - val_loss: 1.3575 - val_accuracy: 0.6316\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 1.3545 - accuracy: 0.6256 - val_loss: 1.3369 - val_accuracy: 0.6316\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 1.3342 - accuracy: 0.6256 - val_loss: 1.3171 - val_accuracy: 0.6316\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 1.3148 - accuracy: 0.6256 - val_loss: 1.2981 - val_accuracy: 0.6316\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.2961 - accuracy: 0.6256 - val_loss: 1.2798 - val_accuracy: 0.6316\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 1.2781 - accuracy: 0.6256 - val_loss: 1.2622 - val_accuracy: 0.6316\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 1.2607 - accuracy: 0.6256 - val_loss: 1.2453 - val_accuracy: 0.6316\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.2441 - accuracy: 0.6256 - val_loss: 1.2290 - val_accuracy: 0.6316\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.2281 - accuracy: 0.6256 - val_loss: 1.2134 - val_accuracy: 0.6316\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.2127 - accuracy: 0.6256 - val_loss: 1.1982 - val_accuracy: 0.6316\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 1.1978 - accuracy: 0.6256 - val_loss: 1.1837 - val_accuracy: 0.6316\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 1.1834 - accuracy: 0.6256 - val_loss: 1.1696 - val_accuracy: 0.6316\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.1695 - accuracy: 0.6256 - val_loss: 1.1561 - val_accuracy: 0.6316\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 1.1562 - accuracy: 0.6256 - val_loss: 1.1430 - val_accuracy: 0.6316\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 53us/step - loss: 1.1432 - accuracy: 0.6256 - val_loss: 1.1304 - val_accuracy: 0.6316\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.1308 - accuracy: 0.6256 - val_loss: 1.1182 - val_accuracy: 0.6316\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.1187 - accuracy: 0.6256 - val_loss: 1.1064 - val_accuracy: 0.6316\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.1070 - accuracy: 0.6256 - val_loss: 1.0950 - val_accuracy: 0.6316\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.0958 - accuracy: 0.6256 - val_loss: 1.0839 - val_accuracy: 0.6316\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.0848 - accuracy: 0.6256 - val_loss: 1.0732 - val_accuracy: 0.6316\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.0743 - accuracy: 0.6256 - val_loss: 1.0628 - val_accuracy: 0.6316\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.0640 - accuracy: 0.6256 - val_loss: 1.0528 - val_accuracy: 0.6316\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.0540 - accuracy: 0.6256 - val_loss: 1.0430 - val_accuracy: 0.6316\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.0442 - accuracy: 0.6256 - val_loss: 1.0335 - val_accuracy: 0.6316\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.0348 - accuracy: 0.6256 - val_loss: 1.0244 - val_accuracy: 0.6316\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 1.0259 - accuracy: 0.6256 - val_loss: 1.0155 - val_accuracy: 0.6316\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.0170 - accuracy: 0.6256 - val_loss: 1.0069 - val_accuracy: 0.6316\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 1.0085 - accuracy: 0.6256 - val_loss: 0.9984 - val_accuracy: 0.6316\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 1.0001 - accuracy: 0.6256 - val_loss: 0.9903 - val_accuracy: 0.6316\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.9920 - accuracy: 0.6256 - val_loss: 0.9824 - val_accuracy: 0.6316\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.9841 - accuracy: 0.6256 - val_loss: 0.9747 - val_accuracy: 0.6316\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.9765 - accuracy: 0.6256 - val_loss: 0.9671 - val_accuracy: 0.6316\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.9690 - accuracy: 0.6256 - val_loss: 0.9597 - val_accuracy: 0.6316\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.9617 - accuracy: 0.6256 - val_loss: 0.9526 - val_accuracy: 0.6316\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.9545 - accuracy: 0.6256 - val_loss: 0.9457 - val_accuracy: 0.6316\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.9476 - accuracy: 0.6256 - val_loss: 0.9389 - val_accuracy: 0.6316\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.9409 - accuracy: 0.6256 - val_loss: 0.9322 - val_accuracy: 0.6316\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.9343 - accuracy: 0.6256 - val_loss: 0.9258 - val_accuracy: 0.6316\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 55us/step - loss: 0.9279 - accuracy: 0.6256 - val_loss: 0.9195 - val_accuracy: 0.6316\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.9216 - accuracy: 0.6256 - val_loss: 0.9134 - val_accuracy: 0.6316\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.9156 - accuracy: 0.6256 - val_loss: 0.9073 - val_accuracy: 0.6316\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.9095 - accuracy: 0.6256 - val_loss: 0.9014 - val_accuracy: 0.6316\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.9036 - accuracy: 0.6256 - val_loss: 0.8957 - val_accuracy: 0.6316\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.8980 - accuracy: 0.6256 - val_loss: 0.8902 - val_accuracy: 0.6316\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.8924 - accuracy: 0.6256 - val_loss: 0.8847 - val_accuracy: 0.6316\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 50us/step - loss: 0.8869 - accuracy: 0.6256 - val_loss: 0.8793 - val_accuracy: 0.6316\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.8816 - accuracy: 0.6256 - val_loss: 0.8741 - val_accuracy: 0.6316\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.8764 - accuracy: 0.6256 - val_loss: 0.8689 - val_accuracy: 0.6316\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.8713 - accuracy: 0.6256 - val_loss: 0.8639 - val_accuracy: 0.6316\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.8663 - accuracy: 0.6256 - val_loss: 0.8590 - val_accuracy: 0.6316\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.8613 - accuracy: 0.6256 - val_loss: 0.8541 - val_accuracy: 0.6316\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 40us/step - loss: 0.8564 - accuracy: 0.6256 - val_loss: 0.8494 - val_accuracy: 0.6316\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.8517 - accuracy: 0.6256 - val_loss: 0.8447 - val_accuracy: 0.6316\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 48us/step - loss: 0.8471 - accuracy: 0.6256 - val_loss: 0.8401 - val_accuracy: 0.6316\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.8426 - accuracy: 0.6256 - val_loss: 0.8357 - val_accuracy: 0.6316\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.8381 - accuracy: 0.6256 - val_loss: 0.8313 - val_accuracy: 0.6316\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.8338 - accuracy: 0.6256 - val_loss: 0.8270 - val_accuracy: 0.6316\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 38us/step - loss: 0.8295 - accuracy: 0.6256 - val_loss: 0.8228 - val_accuracy: 0.6316\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.8253 - accuracy: 0.6256 - val_loss: 0.8186 - val_accuracy: 0.6316\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 45us/step - loss: 0.8211 - accuracy: 0.6256 - val_loss: 0.8144 - val_accuracy: 0.6316\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.8122 - accuracy: 0.62 - 0s 45us/step - loss: 0.8169 - accuracy: 0.6256 - val_loss: 0.8104 - val_accuracy: 0.6316\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.8129 - accuracy: 0.6256 - val_loss: 0.8064 - val_accuracy: 0.6316\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.8089 - accuracy: 0.6256 - val_loss: 0.8025 - val_accuracy: 0.6316\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 43us/step - loss: 0.8050 - accuracy: 0.6256 - val_loss: 0.7986 - val_accuracy: 0.6316\n"
     ]
    }
   ],
   "source": [
    "modelSeq = Sequential() \n",
    "modelSeq.add(Dense(10, input_dim=2,activation='softmax')) \n",
    "modelSeq.add(Dense(20, activation='softmax')) \n",
    "modelSeq.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) \n",
    "history=modelSeq.fit(X_train, y_train,epochs=100, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 29us/step\n",
      "PCA - Neural Network Accuracy = 63.16%\n"
     ]
    }
   ],
   "source": [
    "pred_ANN = modelSeq.predict(X_test) \n",
    "seqEvaluate=modelSeq.evaluate(X_test,y_test)[1] \n",
    "print(\"PCA - Neural Network Accuracy = {0:.2f}%\".format(seqEvaluate*100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Model Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='test accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
